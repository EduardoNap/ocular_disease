{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":161856668,"sourceType":"kernelVersion"}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-24T19:58:02.457458Z","iopub.execute_input":"2024-02-24T19:58:02.458224Z","iopub.status.idle":"2024-02-24T19:58:02.864720Z","shell.execute_reply.started":"2024-02-24T19:58:02.458186Z","shell.execute_reply":"2024-02-24T19:58:02.863860Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/augmented-eyes-4/dataframe_bueno.pkl\n/kaggle/input/augmented-eyes-4/y_train.npy\n/kaggle/input/augmented-eyes-4/X2_train.npy\n/kaggle/input/augmented-eyes-4/name_file_test.npy\n/kaggle/input/augmented-eyes-4/y_test.npy\n/kaggle/input/augmented-eyes-4/__results__.html\n/kaggle/input/augmented-eyes-4/name_file_train.npy\n/kaggle/input/augmented-eyes-4/dataframe.pkl\n/kaggle/input/augmented-eyes-4/X2_test.npy\n/kaggle/input/augmented-eyes-4/X1_train.npy\n/kaggle/input/augmented-eyes-4/__notebook__.ipynb\n/kaggle/input/augmented-eyes-4/X1_test.npy\n/kaggle/input/augmented-eyes-4/__output__.json\n/kaggle/input/augmented-eyes-4/X0_test.npy\n/kaggle/input/augmented-eyes-4/X0_train.npy\n/kaggle/input/augmented-eyes-4/custom.css\n/kaggle/input/augmented-eyes-4/__results___files/__results___13_0.png\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn import metrics\nfrom sklearn.preprocessing import OneHotEncoder\nimport tensorflow as tf\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda\nfrom keras.models import Model\nfrom keras.layers import BatchNormalization, concatenate\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2024-02-24T19:58:02.866203Z","iopub.execute_input":"2024-02-24T19:58:02.866591Z","iopub.status.idle":"2024-02-24T19:58:15.359144Z","shell.execute_reply.started":"2024-02-24T19:58:02.866566Z","shell.execute_reply":"2024-02-24T19:58:15.358136Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-02-24 19:58:05.161325: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-24 19:58:05.161429: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-24 19:58:05.293992: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"%pip install -q -U keras-tuner","metadata":{"execution":{"iopub.status.busy":"2024-02-24T19:58:15.361098Z","iopub.execute_input":"2024-02-24T19:58:15.362058Z","iopub.status.idle":"2024-02-24T19:58:28.463324Z","shell.execute_reply.started":"2024-02-24T19:58:15.362023Z","shell.execute_reply":"2024-02-24T19:58:28.462182Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"width = 224\nheight = 224\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2024-02-24T19:58:28.464698Z","iopub.execute_input":"2024-02-24T19:58:28.464994Z","iopub.status.idle":"2024-02-24T19:58:28.469805Z","shell.execute_reply.started":"2024-02-24T19:58:28.464969Z","shell.execute_reply":"2024-02-24T19:58:28.468783Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def load_data(file_x0,file_x1,file_x2, file_y):\n    \"\"\"\n        Reading numpy data files\n    \"\"\"\n\n    X0 = np.load('/kaggle/input/augmented-eyes-4/'+file_x0)\n    X1 = np.load('/kaggle/input/augmented-eyes-4/'+file_x1)\n    X2 = np.load('/kaggle/input/augmented-eyes-4/'+file_x2)\n    y = np.load('/kaggle/input/augmented-eyes-4/'+file_y)\n    \n    ohe = OneHotEncoder()\n    X2 = ohe.fit_transform(X2.reshape(-1,1)).toarray()\n    y = ohe.fit_transform(y.reshape(-1,1)).toarray()\n     \n    return (X0 , X1, X2, y)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T19:58:28.472539Z","iopub.execute_input":"2024-02-24T19:58:28.473033Z","iopub.status.idle":"2024-02-24T19:58:28.480359Z","shell.execute_reply.started":"2024-02-24T19:58:28.472999Z","shell.execute_reply":"2024-02-24T19:58:28.479456Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#  Load data, and change type for speed\n\n(X0_train, X1_train, X2_train, y_train)= load_data('X0_train.npy', 'X1_train.npy',\n                                                   'X2_train.npy', 'y_train.npy')\n(X0_test, X1_test, X2_test, y_test)= load_data('X0_test.npy', 'X1_test.npy',\n                                                   'X2_test.npy', 'y_test.npy')\n\nX0_train = X0_train.astype('uint8')\nX0_test = X0_test.astype('uint8')\n\nX1_train = X1_train.astype('uint8')\nX1_test = X1_test.astype('uint8')\n\nX2_train = X2_train.astype('uint8')\nX2_test = X2_test.astype('uint8')\n\ny_test = y_test.astype('uint8')\ny_train = y_train.astype('uint8')","metadata":{"execution":{"iopub.status.busy":"2024-02-24T19:58:28.481514Z","iopub.execute_input":"2024-02-24T19:58:28.481775Z","iopub.status.idle":"2024-02-24T19:58:56.558776Z","shell.execute_reply.started":"2024-02-24T19:58:28.481753Z","shell.execute_reply":"2024-02-24T19:58:56.557713Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Reshape ages to be a 2D array\nX1_train = X1_train.reshape(-1, 1)\nX1_test = X1_test.reshape(-1, 1)\n\n# Combine the arrays\ncombined_train = np.hstack((X1_train, X2_train))\ncombined_test = np.hstack((X1_test, X2_test))","metadata":{"execution":{"iopub.status.busy":"2024-02-24T19:58:56.560019Z","iopub.execute_input":"2024-02-24T19:58:56.560312Z","iopub.status.idle":"2024-02-24T19:58:56.565723Z","shell.execute_reply.started":"2024-02-24T19:58:56.560288Z","shell.execute_reply":"2024-02-24T19:58:56.564705Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Hyperparamter tuning for number of hidden layers and neurons and the learning rate\n\nimport keras_tuner as kt\ndef build_model(hp):\n    \n    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=3, default=2)\n    n_hidden2 = hp.Int(\"n_hidden2\", min_value=0, max_value=4, default=2)\n    n_neurons_1 = hp.Int(\"n_neurons\", min_value=1, max_value=32)\n    n_neurons_2 = hp.Int(\"n_neurons2\", min_value=1, max_value=64)\n    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2,\n                             sampling=\"log\")\n    \n    dropout_rate = hp.Float(\"dropout_rate\", min_value=0.25, max_value=0.8)\n    dropout_rate2 = hp.Float(\"dropout_rate2\", min_value=0.1, max_value=0.75)\n    \n    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n    if optimizer == \"sgd\":\n        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, \n                                            momentum=0.9, nesterov=True)\n    else:\n        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate,\n                                             beta_1=0.9, beta_2=0.999, epsilon=1e-7)\n    \n    # MLP Model\n    \n    mlp_input = Input(shape=(3,))\n    mlp = mlp_input  # Initialize mlp here\n    for _ in range(n_hidden):\n        mlp = Dense(units=n_neurons_1, activation='relu')(mlp)\n    mlp = Dense(units=1, activation='relu')(mlp)\n    \n    # CNN Model\n    input_l = Input(X0_train.shape[1:])\n    base_model = VGG16(input_shape =  X0_train.shape[1:], include_top = False, weights = 'imagenet')\n    base_model.trainable = True\n    pt_features = base_model(input_l)\n    bn_features = BatchNormalization()(pt_features)\n    pt_depth = base_model.get_output_shape_at(0)[-1]\n\n    attn_layer = Conv2D(64, kernel_size = (1,1), padding = 'same', \n                        activation = 'relu')(Dropout(dropout_rate)(bn_features))\n    attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', \n                        activation = 'relu')(attn_layer)\n    attn_layer = Conv2D(8, kernel_size = (1,1), padding = 'same', \n                        activation = 'relu')(attn_layer)\n    attn_layer = Conv2D(1, kernel_size = (1,1), padding = 'valid', \n                        activation = 'sigmoid')(attn_layer)\n\n    up_c2_w = np.ones((1, 1, 1, pt_depth))\n    up_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', \n                   activation = 'linear', use_bias = False, weights = [up_c2_w])\n    up_c2.trainable = False\n    attn_layer = up_c2(attn_layer)\n\n\n    mask_features = multiply([attn_layer, bn_features])\n    gap_features = GlobalAveragePooling2D()(mask_features)\n    gap_mask = GlobalAveragePooling2D()(attn_layer)\n\n    # to account for missing values from the attention model\n    gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n    gap_dr = Dropout(dropout_rate2)(gap)\n    dr_steps = Dropout(dropout_rate2)(Dense(128, activation = 'relu')(gap_dr))\n    #cnn_flatten = Flatten()(dr_steps)\n    \n    combined_layer = concatenate([mlp, dr_steps])\n    dense = combined_layer  # Initialize dense here\n    for _ in range(n_hidden2):\n        dense = Dense(units=n_neurons_2, activation='relu')(dense)\n    out_layer = Dense(y_train.shape[-1], activation='softmax')(dense)\n\n    model = Model(inputs=[mlp_input, input_l], outputs=out_layer)\n    \n    metrics = [tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n                   tf.keras.metrics.Precision(name='precision'),\n                   tf.keras.metrics.Recall(name='recall')]\n\n    model.compile(optimizer = optimizer, loss = 'categorical_crossentropy',\n                           metrics = metrics)\n    return model\n    ","metadata":{"execution":{"iopub.status.busy":"2024-02-24T19:59:07.125213Z","iopub.execute_input":"2024-02-24T19:59:07.125949Z","iopub.status.idle":"2024-02-24T19:59:07.475693Z","shell.execute_reply.started":"2024-02-24T19:59:07.125913Z","shell.execute_reply":"2024-02-24T19:59:07.474848Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Add some constraints and search\nweight_path=\"{}_weights.best.hdf5\".format('retina')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=3, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\nearly = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\ncallbacks_list = [checkpoint, early, reduceLROnPlat]\n\nhyperband = kt.Hyperband(\n    build_model, objective=\"val_accuracy\",\n    max_epochs=10, factor=3, hyperband_iterations=2,\n    overwrite=True, directory=\"/kaggle/working/\", project_name=\"hyperband\")\n\nhistory = hyperband.search(x=[combined_train, X0_train], y=y_train, epochs=12, verbose=1,\n                                               callbacks=callbacks_list,\n                                               shuffle=True, validation_data=([combined_test, X0_test], y_test))","metadata":{"execution":{"iopub.status.busy":"2024-02-24T19:59:14.588848Z","iopub.execute_input":"2024-02-24T19:59:14.589176Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Trial 30 Complete [00h 26m 58s]\nval_accuracy: 0.6581140160560608\n\nBest val_accuracy So Far: 0.8002192974090576\nTotal elapsed time: 05h 31m 35s\n\nSearch: Running Trial #31\n\nValue             |Best Value So Far |Hyperparameter\n3                 |3                 |n_hidden\n1                 |0                 |n_hidden2\n31                |7                 |n_neurons\n36                |57                |n_neurons2\n0.0018682         |0.00042746        |learning_rate\n0.51271           |0.46634           |dropout_rate\n0.45365           |0.3767            |dropout_rate2\nadam              |sgd               |optimizer\n2                 |10                |tuner/epochs\n0                 |0                 |tuner/initial_epoch\n2                 |0                 |tuner/bracket\n0                 |0                 |tuner/round\n\nEpoch 1/2\n","output_type":"stream"},{"name":"stderr","text":"2024-02-25 01:31:01.912970: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":" 91/570 [===>..........................] - ETA: 2:07 - loss: 2.0829 - accuracy: 0.1569 - precision: 0.4000 - recall: 0.0014","output_type":"stream"}]},{"cell_type":"code","source":"# Save the best model\ntop3_models = random_search_tuner.get_best_models(num_models=3)\nbest_model = top3_models[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the best hyperparameters\ntop3_params = random_search_tuner.get_best_hyperparameters(num_trials=3)\ntop3_params[0].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}